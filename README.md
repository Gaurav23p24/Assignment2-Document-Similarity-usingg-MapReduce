# Assignment 2 â€” Document Similarity using MapReduce

**Course:** Cloud Computing for Data Analysis (ITCS 6190/8190, Fall 2025)  
**Instructor:** Marco Vieira  
**Student:** Gaurav Bharatkumar Patel (801426641)

---

## ğŸ“Œ Overview

This project computes **pairwise Jaccard Similarity** between documents using **Hadoop MapReduce**.  
Each line of the input file contains a `DocumentID` followed by its text. The pipeline:

1. **Parses** each line, normalizes case, and removes punctuation.
2. **Builds sets of unique tokens** per document.
3. **Counts intersections** of document pairs via shared tokens across reducers.
4. **Computes** Jaccard = \|A âˆ© B\| / \|A âˆª B\| and outputs `DocumentX, DocumentY  Similarity: s.xx`.

---

## ğŸ§  Approach & Implementation

### Mapper (`DocumentSimilarityMapper`)
- **Input:** `(LongWritable offset, Text line)`
- **Steps:**
  1. Split into `docID` and `content`.
  2. Normalize: lowercase + strip punctuation.
  3. Tokenize and insert into a `HashSet<String>` to get **unique** terms; size â‡’ `docSize`.
  4. **Emit:** `(word, "docID:docSize")` for every unique word in the document.
- **Example emit:** `("spark", "Document12:157")`

### Reducer (`DocumentSimilarityReducer`)
- **Input:** `key = word`, `values = ["docID:docSize", ...]`
- **reduce()**
  - For the given `word`, collect all `(docID, docSize)` pairs.
  - Record per-document sizes in `docSizes: Map<String,Integer>`.
  - Generate **unique pairs** among docs containing `word` and increment  
    `intersectionCounts: Map<Pair, Integer>` for that pair.
- **cleanup()**
  - For each pair `(A,B)` in `intersectionCounts`:
    - `inter = intersectionCounts[A,B]`
    - `|A| = docSizes[A]`, `|B| = docSizes[B]`
    - `union = |A| + |B| - inter`
    - `jaccard = inter / union` â†’ **rounded to two decimals**
  - **Emit:** `"A,B"  â†’  "Similarity: 0.xx"`

> This single job approach avoids materializing all pairs in the mapper and leverages reducer-side aggregation of intersections.

---

## ğŸ—‚ï¸ Repository Layout

```text
Assignment2-Document-Similarity-usingg-MapReduce/
â”œâ”€ src/
â”‚  â””â”€ main/
â”‚     â””â”€ java/
â”‚        â””â”€ com/
â”‚           â””â”€ example/
â”‚              â”œâ”€ mapper/
â”‚              â”‚  â””â”€ DocumentSimilarityMapper.java
â”‚              â”œâ”€ reducer/
â”‚              â”‚  â””â”€ DocumentSimilarityReducer.java
â”‚              â””â”€ controller/
â”‚                 â””â”€ DocumentSimilarityDriver.java
â”œâ”€ input/
â”‚  â”œâ”€ small_dataset.txt
â”‚  â”œâ”€ medium_dataset.txt
â”‚  â””â”€ large_dataset.txt
â”œâ”€ outputs/
â”‚  â”œâ”€ 3nodes/
â”‚  â”‚  â”œâ”€ small_results.txt
â”‚  â”‚  â”œâ”€ medium_results.txt
â”‚  â”‚  â””â”€ large_results.txt
â”‚  â””â”€ 1node/
â”‚     â”œâ”€ small_results_1node.txt
â”‚     â”œâ”€ medium_results_1node.txt
â”‚     â””â”€ large_results_1node.txt
â”œâ”€ docker-compose.yml
â”œâ”€ pom.xml
â”œâ”€ README.md
â””â”€ target/                    # generated by Maven; usually not committed
   â””â”€ DocumentSimilarity-0.0.1-SNAPSHOT.jar


---

## Sample Outputs (Truncated)

### Small Dataset
| Document Pair | Similarity |
|--------------|-----------|
| Document10,Document19 | 0.42 |
| Document20,Document3  | 0.53 |
| Document10,Document18 | 0.50 |
| Document20,Document4  | 0.63 |
| Document20,Document5  | 0.61 |
| Document7,Document9   | 0.60 |
| Document13,Document16 | 0.67 |
| Document18,Document6  | 0.83 |
| Document1,Document15  | 0.69 |
| Document4,Document7   | 0.74 |

---

### Medium Dataset
| Document Pair | Similarity |
|--------------|-----------|
| Document13,Document2  | 0.84 |
| Document22,Document4  | 0.89 |
| Document22,Document27 | 0.90 |
| Document2,Document24  | 0.95 |
| Document32,Document47 | 0.85 |
| Document25,Document36 | 1.00 |
| Document47,Document7  | 0.89 |
| Document16,Document30 | 0.95 |
| Document23,Document6  | 0.88 |
| Document27,Document4  | 0.90 |

---

### Large Dataset
| Document Pair | Similarity |
|--------------|-----------|
| Document89,Document96 | 0.95 |
| Document62,Document74 | 0.89 |
| Document71,Document78 | 1.00 |
| Document31,Document79 | 0.95 |
| Document48,Document66 | 1.00 |
| Document48,Document73 | 1.00 |
| Document18,Document71 | 0.95 |
| Document18,Document99 | 1.00 |
| Document65,Document84 | 0.95 |
| Document48,Document85 | 1.00 |


---

## Challenges & Actions Taken

| Challenge | Action Taken |
|----------|--------------|
| **ClassNotFoundException for Driver Class** | Initially, the JAR built with Maven could not locate the `DocumentSimilarityDriver`. This happened because the Java files were placed directly under `src/main/` instead of `src/main/java/`. After restructuring the project to follow the Maven convention and rebuilding, the JAR executed successfully. |
| **JAR Missing After Docker Restart** | Each `docker compose down` removed the container, wiping the previously copied JAR. The solution was to always re-copy the built JAR into the namenode container after starting the cluster. |
| **HDFS Output Not Accessible from Host** | Attempting to `docker cp` results directly from `/output` failed because Hadoop stores job outputs in HDFS. The fix was to first use `hdfs dfs -get` inside the namenode to copy results to the containerâ€™s local filesystem, and then use `docker cp` to bring them to the Codespace host. |
| **Performance Measurement Across Clusters** | Needed accurate timing to compare 3-node vs 1-node runs. Used the shellâ€™s built-in `time` command to measure job runtime for each dataset, recording map + reduce execution times. |
| **Overwriting Inputs During Iteration** | While re-running tests with updated datasets, old HDFS inputs conflicted. Solved this by using `hdfs dfs -put -f` which overwrites existing files safely. |
